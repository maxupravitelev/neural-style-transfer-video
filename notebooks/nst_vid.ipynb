{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X9uqTXA-guxV",
        "outputId": "d8aa3dcc-b84d-4ddf-a52c-78a3ad38481b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.0.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.8.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.0.1)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.13.3)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.2)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.12.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.37.0)\n",
            "Requirement already satisfied: tensorboard<2.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.21.5)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.17.3)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.42.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.0.8)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow) (2.10.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow) (3.3.6)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow) (1.35.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow) (57.4.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow) (4.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.1.0,>=2.0.0->tensorflow) (4.8.2)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.1.0,>=2.0.0->tensorflow) (3.10.0.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.1.0,>=2.0.0->tensorflow) (3.6.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow) (3.1.1)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (4.1.2.30)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python) (1.21.5)\n",
            "Requirement already satisfied: tensorflow_hub in /usr/local/lib/python3.7/dist-packages (0.12.0)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_hub) (1.21.5)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_hub) (3.17.3)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.8.0->tensorflow_hub) (1.16.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (3.2.2)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.21.5)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (3.0.6)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib) (1.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.21.5)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (7.1.2)\n"
          ]
        }
      ],
      "source": [
        "#@title Setup app\n",
        "!pip install tensorflow\n",
        "!pip install opencv-python\n",
        "!pip install tensorflow_hub\n",
        "!pip install matplotlib\n",
        "!pip install numpy\n",
        "!pip install Pillow\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vsZlJJVzQ_KR"
      },
      "source": [
        "Click \"Restart Runtime\" after the cell above has been executed."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The output video files have a rather low resolution, due to how the actual neural style transfer is handled. You can upscale the video files either by simple upscaling or by utilizing the [Image Super Resolution](https://github.com/idealo/image-super-resolution) package. If you want to use the latter, please run the cell below and click on \"Restart Runtime\" once it's done."
      ],
      "metadata": {
        "id": "qbfscJz8zAB_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Optional: Install the Image Super Resolution package\n",
        "!pip install ISR\n",
        "!pip install 'h5py==2.10.0' --force-reinstall\n"
      ],
      "metadata": {
        "id": "DuDJ44JdzDk6",
        "outputId": "29258e11-3c2f-401b-8d32-7c4de1e89070",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ISR\n",
            "  Downloading ISR-2.2.0-py3-none-any.whl (33 kB)\n",
            "Collecting pyaml\n",
            "  Downloading pyaml-21.10.1-py2.py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.7/dist-packages (from ISR) (2.4.1)\n",
            "Collecting tensorflow==2.0.0\n",
            "  Downloading tensorflow-2.0.0-cp37-cp37m-manylinux2010_x86_64.whl (86.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 86.3 MB 38 kB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from ISR) (4.62.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from ISR) (1.19.5)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0->ISR) (1.1.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0->ISR) (0.2.0)\n",
            "Collecting tensorflow-estimator<2.1.0,>=2.0.0\n",
            "  Downloading tensorflow_estimator-2.0.1-py2.py3-none-any.whl (449 kB)\n",
            "\u001b[K     |████████████████████████████████| 449 kB 41.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0->ISR) (0.37.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0->ISR) (1.42.0)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading gast-0.2.2.tar.gz (10 kB)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0->ISR) (0.12.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0->ISR) (3.3.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0->ISR) (3.17.3)\n",
            "Collecting keras-applications>=1.0.8\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 2.2 MB/s \n",
            "\u001b[?25hCollecting tensorboard<2.1.0,>=2.0.0\n",
            "  Downloading tensorboard-2.0.2-py3-none-any.whl (3.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 35.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0->ISR) (0.8.1)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0->ISR) (1.13.3)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0->ISR) (1.1.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0->ISR) (1.15.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow==2.0.0->ISR) (3.1.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0->ISR) (3.3.6)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0->ISR) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0->ISR) (57.4.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0->ISR) (0.4.6)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0->ISR) (1.35.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0->ISR) (2.23.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0->ISR) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0->ISR) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0->ISR) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0->ISR) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0->ISR) (4.8.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0->ISR) (3.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0->ISR) (3.10.0.2)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0->ISR) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0->ISR) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0->ISR) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0->ISR) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0->ISR) (2021.10.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0->ISR) (3.1.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.8->tensorflow==2.0.0->ISR) (1.5.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from imageio->ISR) (7.1.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from pyaml->ISR) (3.13)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-py3-none-any.whl size=7554 sha256=2a1b57458ddc072356c1c6da00e1a2a24de62d5cd8df25aba4a827b90b6f331e\n",
            "  Stored in directory: /root/.cache/pip/wheels/21/7f/02/420f32a803f7d0967b48dd823da3f558c5166991bfd204eef3\n",
            "Successfully built gast\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, keras-applications, gast, tensorflow, pyaml, ISR\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.7.0\n",
            "    Uninstalling tensorflow-estimator-2.7.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.7.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.7.0\n",
            "    Uninstalling tensorboard-2.7.0:\n",
            "      Successfully uninstalled tensorboard-2.7.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.4.0\n",
            "    Uninstalling gast-0.4.0:\n",
            "      Successfully uninstalled gast-0.4.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.7.0\n",
            "    Uninstalling tensorflow-2.7.0:\n",
            "      Successfully uninstalled tensorflow-2.7.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-probability 0.15.0 requires gast>=0.3.2, but you have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "Successfully installed ISR-2.2.0 gast-0.2.2 keras-applications-1.0.8 pyaml-21.10.1 tensorboard-2.0.2 tensorflow-2.0.0 tensorflow-estimator-2.0.1\n",
            "Collecting h5py==2.10.0\n",
            "  Downloading h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 5.1 MB/s \n",
            "\u001b[?25hCollecting six\n",
            "  Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
            "Collecting numpy>=1.7\n",
            "  Downloading numpy-1.21.5-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 15.7 MB 46.6 MB/s \n",
            "\u001b[?25hInstalling collected packages: six, numpy, h5py\n",
            "  Attempting uninstall: six\n",
            "    Found existing installation: six 1.15.0\n",
            "    Uninstalling six-1.15.0:\n",
            "      Successfully uninstalled six-1.15.0\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.19.5\n",
            "    Uninstalling numpy-1.19.5:\n",
            "      Successfully uninstalled numpy-1.19.5\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.1.0\n",
            "    Uninstalling h5py-3.1.0:\n",
            "      Successfully uninstalled h5py-3.1.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "yellowbrick 1.3.post1 requires numpy<1.20,>=1.16.0, but you have numpy 1.21.5 which is incompatible.\n",
            "tensorflow-probability 0.15.0 requires gast>=0.3.2, but you have gast 0.2.2 which is incompatible.\n",
            "google-colab 1.0.0 requires six~=1.15.0, but you have six 1.16.0 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed h5py-2.10.0 numpy-1.21.5 six-1.16.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy",
                  "six"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w9qX1X4Kh26u",
        "outputId": "651a4bba-f0fc-4f99-91ee-3d2890d124b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2021-12-30:10:55:34 | DEBUG | __main__ | LINE 25: Logging initialized\n",
            "2021-12-30:10:55:34 | DEBUG | __main__ | LINE 37: FrameExtractor initialized\n",
            "2021-12-30:10:55:34 | DEBUG | __main__ | LINE 79: 0 frames extracted\n",
            "2021-12-30:10:55:34 | DEBUG | __main__ | LINE 79: 1 frames extracted\n",
            "2021-12-30:10:55:34 | DEBUG | __main__ | LINE 79: 2 frames extracted\n",
            "2021-12-30:10:55:34 | DEBUG | __main__ | LINE 79: 3 frames extracted\n",
            "2021-12-30:10:55:35 | DEBUG | __main__ | LINE 79: 4 frames extracted\n",
            "2021-12-30:10:55:35 | DEBUG | __main__ | LINE 79: 5 frames extracted\n",
            "2021-12-30:10:55:35 | INFO | __main__ | LINE 82: 6 images are extracted in output/extracted_frames/testvid.\n",
            "2021-12-30:10:55:38 | DEBUG | __main__ | LINE 114: NeuralStyleTransferHandler initialized\n",
            "2021-12-30:10:55:41 | DEBUG | __main__ | LINE 215: 0 frames stylized\n",
            "2021-12-30:10:55:42 | DEBUG | __main__ | LINE 215: 1 frames stylized\n",
            "2021-12-30:10:55:44 | DEBUG | __main__ | LINE 215: 2 frames stylized\n",
            "2021-12-30:10:55:46 | DEBUG | __main__ | LINE 215: 3 frames stylized\n",
            "2021-12-30:10:55:47 | DEBUG | __main__ | LINE 215: 4 frames stylized\n",
            "2021-12-30:10:55:49 | DEBUG | __main__ | LINE 215: 5 frames stylized\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "superres\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2021-12-30:10:55:50 | DEBUG | PIL.PngImagePlugin | LINE 153: STREAM b'IHDR' 16 13\n",
            "2021-12-30:10:55:50 | DEBUG | PIL.PngImagePlugin | LINE 153: STREAM b'IDAT' 41 65536\n",
            "2021-12-30:10:55:55 | DEBUG | __main__ | LINE 291: 0 frames resized\n",
            "2021-12-30:10:55:55 | DEBUG | __main__ | LINE 291: None\n",
            "2021-12-30:10:55:55 | DEBUG | PIL.PngImagePlugin | LINE 153: STREAM b'IHDR' 16 13\n",
            "2021-12-30:10:55:55 | DEBUG | PIL.PngImagePlugin | LINE 153: STREAM b'IDAT' 41 65536\n",
            "2021-12-30:10:56:01 | DEBUG | __main__ | LINE 291: 1 frames resized\n",
            "2021-12-30:10:56:01 | DEBUG | __main__ | LINE 291: None\n",
            "2021-12-30:10:56:01 | DEBUG | PIL.PngImagePlugin | LINE 153: STREAM b'IHDR' 16 13\n",
            "2021-12-30:10:56:01 | DEBUG | PIL.PngImagePlugin | LINE 153: STREAM b'IDAT' 41 65536\n",
            "2021-12-30:10:56:06 | DEBUG | __main__ | LINE 291: 2 frames resized\n",
            "2021-12-30:10:56:06 | DEBUG | __main__ | LINE 291: None\n",
            "2021-12-30:10:56:06 | DEBUG | PIL.PngImagePlugin | LINE 153: STREAM b'IHDR' 16 13\n",
            "2021-12-30:10:56:06 | DEBUG | PIL.PngImagePlugin | LINE 153: STREAM b'IDAT' 41 65536\n",
            "2021-12-30:10:56:11 | DEBUG | __main__ | LINE 291: 3 frames resized\n",
            "2021-12-30:10:56:11 | DEBUG | __main__ | LINE 291: None\n",
            "2021-12-30:10:56:11 | DEBUG | PIL.PngImagePlugin | LINE 153: STREAM b'IHDR' 16 13\n",
            "2021-12-30:10:56:11 | DEBUG | PIL.PngImagePlugin | LINE 153: STREAM b'IDAT' 41 65536\n",
            "2021-12-30:10:56:17 | DEBUG | __main__ | LINE 291: 4 frames resized\n",
            "2021-12-30:10:56:17 | DEBUG | __main__ | LINE 291: None\n",
            "2021-12-30:10:56:17 | DEBUG | PIL.PngImagePlugin | LINE 153: STREAM b'IHDR' 16 13\n",
            "2021-12-30:10:56:17 | DEBUG | PIL.PngImagePlugin | LINE 153: STREAM b'IDAT' 41 65536\n",
            "2021-12-30:10:56:22 | DEBUG | __main__ | LINE 291: 5 frames resized\n",
            "2021-12-30:10:56:22 | DEBUG | __main__ | LINE 291: None\n",
            "2021-12-30:10:56:22 | DEBUG | __main__ | LINE 303: FrameCombiner initialized\n",
            "2021-12-30:10:56:22 | DEBUG | __main__ | LINE 319: 0 frames combined\n",
            "2021-12-30:10:56:22 | DEBUG | __main__ | LINE 319: 1 frames combined\n",
            "2021-12-30:10:56:22 | DEBUG | __main__ | LINE 319: 2 frames combined\n",
            "2021-12-30:10:56:22 | DEBUG | __main__ | LINE 319: 3 frames combined\n",
            "2021-12-30:10:56:22 | DEBUG | __main__ | LINE 319: 4 frames combined\n",
            "2021-12-30:10:56:22 | DEBUG | __main__ | LINE 319: 5 frames combined\n"
          ]
        }
      ],
      "source": [
        "#@title Run the app\n",
        "import os\n",
        "import cv2\n",
        "import logging\n",
        "\n",
        "import functools\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "import PIL\n",
        "import os.path\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "input_file_path = \"testvid.mp4\" #@param {type:\"string\"}\n",
        "filter_path = \"frame1.png\" #@param {type:\"string\"}\n",
        "output_max_size = 256 #@param {type:\"number\"}\n",
        "resize_factor = 4 #@param {type:\"number\"}\n",
        "use_superres = True #@param {type:\"boolean\"}\n",
        "\n",
        "logging.basicConfig(level=logging.DEBUG, datefmt='%Y-%m-%d:%H:%M:%S', format='%(asctime)s | %(levelname)s | %(name)s | LINE %(lineno)d: %(message)s')\n",
        "log = logging.getLogger(__name__)\n",
        "log.debug('Logging initialized')\n",
        "\n",
        "\n",
        "class FrameExtractor:\n",
        "    def __init__(self, input_video_path:str) -> None:\n",
        "\n",
        "        self.input_video_path:str = input_video_path\n",
        "\n",
        "        self.input_video_filename:str = ''\n",
        "\n",
        "        self.extracted_frames_path:str = ''\n",
        "\n",
        "        log.debug('FrameExtractor initialized')\n",
        "\n",
        "    def create_subfolder(self):\n",
        "        path_string_length:str = len(self.input_video_path)\n",
        "\n",
        "        self.input_video_filename = self.input_video_path[:path_string_length - 4] # delete file extension from string\n",
        "\n",
        "        parent_dir = 'output/extracted_frames/'\n",
        "\n",
        "        self.extracted_frames_path = os.path.join(parent_dir, self.input_video_filename)\n",
        "\n",
        "        if not os.path.exists(self.extracted_frames_path):\n",
        "            try:\n",
        "                os.makedirs(self.extracted_frames_path)\n",
        "                log.debug(f'Output path for resized frames: {self.extracted_frames_path}')\n",
        "            except Exception as e:\n",
        "                log.error(f'Output path for resized frames FAILED: {e}')\n",
        "\n",
        "\n",
        "\n",
        "    def extract_frames(self) -> str:\n",
        "                \n",
        "        cap = cv2.VideoCapture(self.input_video_path)\n",
        "\n",
        "        ret, frame = cap.read()\n",
        "        \n",
        "        if not ret:\n",
        "            log.error(f'File is not available at: {self.input_video_path}')\n",
        "\n",
        "        self.create_subfolder()\n",
        "        \n",
        "        cap = cv2.VideoCapture(self.input_video_path)\n",
        "\n",
        "        file_count:int = 0\n",
        "\n",
        "        while True:\n",
        "            ret, image = cap.read()\n",
        "\n",
        "            if not ret:\n",
        "                break\n",
        "\n",
        "            cv2.imwrite(os.path.join(self.extracted_frames_path, f\"frame{file_count}.png\"), image)     \n",
        "            log.debug(f\"{file_count} frames extracted\")\n",
        "            file_count += 1\n",
        "\n",
        "        log.info(f\"{file_count} images are extracted in {self.extracted_frames_path}.\")\n",
        "\n",
        "        return self.extracted_frames_path, self.input_video_filename\n",
        "\n",
        "\n",
        "# FrameExtractor('1.mp4').extract_frames()\n",
        "\n",
        "class NeuralStyleTransferHandler:\n",
        "    def __init__(self, extracted_frames_path:str, input_video_filename:str) -> None:\n",
        "        os.environ['CUDA_VISIBLE_DEVICES']='-1'    # disable gpu\n",
        "\n",
        "        # Load TF-Hub module\n",
        "\n",
        "        # TODO: check if downloaded and set up on first startup, load from local afterwards\n",
        "        hub_handle = 'https://tfhub.dev/google/magenta/arbitrary-image-stylization-v1-256/2'\n",
        "        #hub_handle = 'models/arbv1'\n",
        "        self.hub_module = hub.load(hub_handle)\n",
        "\n",
        "        self.extracted_frames_path = extracted_frames_path\n",
        "        self.input_video_filename = input_video_filename\n",
        "\n",
        "        parent_dir = 'output/stylized_frames/'\n",
        "\n",
        "        self.stylized_frames_path = os.path.join(parent_dir, input_video_filename)\n",
        "\n",
        "        if not os.path.exists(self.stylized_frames_path):\n",
        "            try:\n",
        "                os.makedirs(self.stylized_frames_path)\n",
        "                log.debug(f'Output path for stylized frames: {self.stylized_frames_path}')\n",
        "            except Exception as e:\n",
        "                log.error(f'Output path for stylized frames FAILED: {e}')\n",
        "\n",
        "        log.debug('NeuralStyleTransferHandler initialized')\n",
        "\n",
        "\n",
        "    # TODO\n",
        "    # def create_subfolder(self):\n",
        "\n",
        "\n",
        "    def crop_center(self, image):\n",
        "        '''Returns a cropped square image.'''\n",
        "        shape = image.shape\n",
        "        new_shape = min(shape[1], shape[2])\n",
        "        offset_y = max(shape[1] - shape[2], 0) // 2\n",
        "        offset_x = max(shape[2] - shape[1], 0) // 2\n",
        "        image = tf.image.crop_to_bounding_box(\n",
        "            image, offset_y, offset_x, new_shape, new_shape)\n",
        "        return image\n",
        "\n",
        "\n",
        "    def img_scaler(self, image, max_dim = output_max_size):\n",
        "\n",
        "        # Casts a tensor to a new type.\n",
        "        original_shape = tf.cast(tf.shape(image)[:-1], tf.float32)\n",
        "\n",
        "        # Creates a scale constant for the image\n",
        "        scale_ratio = max_dim / max(original_shape)\n",
        "\n",
        "        # Casts a tensor to a new type.\n",
        "        new_shape = tf.cast(original_shape * scale_ratio * 1, tf.int32)\n",
        "\n",
        "        # Resizes the image based on the scaling constant generated above\n",
        "        return tf.image.resize(image, new_shape)\n",
        "\n",
        "\n",
        "    @functools.lru_cache(maxsize=None)\n",
        "    def load_image(self, image_url, image_size=(256, 256), preserve_aspect_ratio=True):\n",
        "        '''Loads and preprocesses images.'''\n",
        "        # Cache image file locally.\n",
        "        #image_path = tf.keras.utils.get_file(os.path.basename(image_url)[-128:], image_url)\n",
        "        image_path = image_url\n",
        "        # Load and convert to float32 numpy array, add batch dimension, and normalize to range [0, 1].\n",
        "        img = tf.io.decode_image(\n",
        "            tf.io.read_file(image_path),\n",
        "            channels=3, dtype=tf.float32)\n",
        "        \n",
        "\n",
        "        #img = crop_center(img)\n",
        "        img = self.img_scaler(img)\n",
        "\n",
        "        #img = tf.image.resize(img, image_size, preserve_aspect_ratio=True)\n",
        "        return img[tf.newaxis, ...]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def stylize_batch(self, mode:str,  filter_path: str):\n",
        "\n",
        "        foldername = self.extracted_frames_path\n",
        "        files_in_folder = len([file for file in os.listdir(f'{foldername}/')])\n",
        "\n",
        "        if mode == \"stylize_by_all_filters\":\n",
        "            stylized_folder = f'output/stylized_frames/{self.input_video_filename}_all_filter'\n",
        "        else: \n",
        "            stylized_folder = f'output/stylized_frames/{self.input_video_filename}'\n",
        "\n",
        "        if not os.path.exists(stylized_folder):\n",
        "            os.mkdir(stylized_folder)\n",
        "\n",
        "        for i in range(files_in_folder):\n",
        "\n",
        "            if mode == 'stylize_by_all_filters':\n",
        "\n",
        "                #content_image_url: str = f'{self.extracted_frames_path}/frame{place_in_folder}.png'\n",
        "                style_image_url: str = f'filter/{i}.jpg'  \n",
        "            \n",
        "            elif mode=='stylize_by_filter':\n",
        "                content_image_url: str = f'{self.extracted_frames_path}/frame{i}.png'\n",
        "                style_image_url: str = filter_path\n",
        "            \n",
        "            output_image_size: int = 512\n",
        "\n",
        "\n",
        "            # The content image size can be arbitrary.\n",
        "            content_img_size = (output_image_size, output_image_size)\n",
        "            # The style prediction model was trained with image size 256 and it's the \n",
        "            # recommended image size for the style image (though, other sizes work as \n",
        "            # well but will lead to different results).\n",
        "            style_img_size = (256, 256)  # Recommended to keep it at 256.\n",
        "\n",
        "            content_image = self.load_image(content_image_url, content_img_size)\n",
        "            style_image = self.load_image(style_image_url, style_img_size)\n",
        "\n",
        "            style_image = tf.nn.avg_pool(style_image, ksize=[3,3], strides=[1,1], padding='SAME')\n",
        "\n",
        "\n",
        "            outputs = self.hub_module(tf.constant(content_image), tf.constant(style_image))\n",
        "\n",
        "            stylized_image = outputs[0]\n",
        "            squeezed_image = tf.squeeze(stylized_image)\n",
        "            \n",
        "            tf.keras.preprocessing.image.save_img(f'{self.stylized_frames_path}/frame{i}.png', squeezed_image)\n",
        "            log.debug(f\"{i} frames stylized\")\n",
        "\n",
        "        return self.stylized_frames_path\n",
        "\n",
        "class ImageResizer:\n",
        "    def __init__(self, styled_frames_path:str, input_video_filename:str) -> None:\n",
        "\n",
        "        self.styled_frames_path = styled_frames_path\n",
        "        self.files_in_folder = len([file for file in os.listdir(f'{self.styled_frames_path}/')])\n",
        "\n",
        "        self.input_video_filename = input_video_filename\n",
        "        \n",
        "        self.resized_frames_path = ''\n",
        "\n",
        "        self.create_subfolder()\n",
        "\n",
        "\n",
        "    def create_subfolder(self):\n",
        "\n",
        "        # path_string_length:str = len(self.input_video_filename)\n",
        "\n",
        "        # self.input_video_filename = self.input_video_filename[:path_string_length - 4] # delete file extension from string\n",
        "\n",
        "        parent_dir = 'output/resized_frames/'\n",
        "\n",
        "        self.resized_frames_path = os.path.join(parent_dir, self.input_video_filename)\n",
        "\n",
        "        if not os.path.exists(self.resized_frames_path):\n",
        "            try:\n",
        "                os.makedirs(self.resized_frames_path)\n",
        "                log.debug(f'Output path for resized frames: {self.resized_frames_path}')\n",
        "            except Exception as e:\n",
        "                log.error(f'Output path for resized frames FAILED: {e}')\n",
        "\n",
        "\n",
        "    def resize(self, resize_factor=2):\n",
        "\n",
        "        for file_count in range(self.files_in_folder):\n",
        "            image_path = self.styled_frames_path + '/' + f'frame{file_count}.png'\n",
        "\n",
        "            img = Image.open(image_path)\n",
        "            img = img.resize((img.size[0] * resize_factor, img.size[1] * resize_factor)) # (width, height)\n",
        "\n",
        "            img.save(self.resized_frames_path + '/' + f'frame{file_count}.png')\n",
        "            \n",
        "            log.debug(f\"{file_count} frames resized\")\n",
        "\n",
        "        return self.resized_frames_path\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def resize_superres(self, resize_factor):\n",
        "\n",
        "        import numpy as np\n",
        "        # import sys\n",
        "        # sys.path.append('..')\n",
        "        from ISR.models import RDN, RRDN\n",
        "\n",
        "        #model = RDN(weights='noise-cancel')\n",
        "        #model = RRDN(weights='gans')\n",
        "        model = RDN(weights='psnr-small')\n",
        "        #model = RDN(weights='psnr-large')\n",
        "\n",
        "        for file_count in range(self.files_in_folder):\n",
        "            image_path = self.styled_frames_path + '/' + f'frame{file_count}.png'\n",
        "\n",
        "            img = Image.open(image_path)\n",
        "\n",
        "            img.resize(size=(img.size[0]*resize_factor, img.size[1]*resize_factor), resample=Image.BICUBIC)\n",
        "            sr_img = model.predict(np.array(img))\n",
        "\n",
        "            new_image = Image.fromarray(sr_img)\n",
        "            new_image.save(f'{self.resized_frames_path}/frame{file_count}.png')\n",
        "            \n",
        "            log.debug(log.debug(f\"{file_count} frames resized\"))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class FrameCombiner:\n",
        "    def __init__(self, styled_frames_path:str, input_video_filename:str) -> None:\n",
        "        \n",
        "        self.styled_frames_path:str = styled_frames_path\n",
        "        self.input_video_filename:str = input_video_filename\n",
        "        \n",
        "        log.debug('FrameCombiner initialized')\n",
        "        \n",
        "\n",
        "    def combine_frames(self, filtername):\n",
        "\n",
        "        img = cv2.imread(f'{self.styled_frames_path}/frame0.png', 0)\n",
        "\n",
        "        # choose codec according to format needed\n",
        "        fourcc = cv2.VideoWriter_fourcc(*'mp4v') \n",
        "        video = cv2.VideoWriter(f'{self.input_video_filename}_stylized_filter{filtername}.mp4', fourcc, 24, (img.shape[1], img.shape[0]))\n",
        "\n",
        "        files_in_folder = len([file for file in os.listdir(f'{self.styled_frames_path}/')])\n",
        "\n",
        "        for frame_count in range(0, files_in_folder):\n",
        "            img = cv2.imread(f'{self.styled_frames_path}/frame{frame_count}.png')\n",
        "            video.write(img)\n",
        "            log.debug(f'{frame_count} frames combined')\n",
        "\n",
        "        cv2.destroyAllWindows()\n",
        "        video.release()\n",
        "\n",
        "\n",
        "def main():\n",
        "\n",
        "    #global filter_path, image_file_path\n",
        "\n",
        "    # extract frames in folder\n",
        "    extracted_frames_path, input_video_filename = FrameExtractor(input_file_path).extract_frames()\n",
        "\n",
        "    # nst all frames in folder\n",
        "    styled_frames_path = NeuralStyleTransferHandler(extracted_frames_path, input_video_filename).stylize_batch('stylize_by_filter', filter_path)\n",
        "\n",
        "    # styled_frames_path = NeuralStyleTransferHandler(extracted_frames_path, input_video_filename).stylize_batch('stylize_by_filter', place_in_folder=filtername)\n",
        "    # styled_frames_path = NeuralStyleTransferHandler(extracted_frames_path='output/extracted_frames/1', input_video_filename='1').stylize_batch('stylize_by_filter', place_in_folder=70)\n",
        "\n",
        "\n",
        "    # optional: resize all frames in folder\n",
        "    if resize_factor is not 1:\n",
        "        if use_superres is True:\n",
        "            resized_frames_path = ImageResizer(styled_frames_path, input_video_filename).resize_superres(resize_factor)\n",
        "        else:\n",
        "            resized_frames_path = ImageResizer(styled_frames_path, input_video_filename).resize(resize_factor)\n",
        "\n",
        "\n",
        "    # combine all frames in video file\n",
        "    FrameCombiner(styled_frames_path, input_video_filename).combine_frames(filter_path)\n",
        "    # test = FrameCombiner(resized_frames_path, input_video_filename).combine_frames(filter_path)\n",
        "    #test = FrameCombiner('output/resized_frames/2', '2').combine_frames(filter_path)\n",
        "\n",
        "\n",
        "main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "k4X_UyJ4p0H6"
      },
      "outputs": [],
      "source": [
        "#@title Download all output as a zip file\n",
        "!zip -r ./output.zip ./output\n",
        "\n",
        "from google.colab import files\n",
        "files.download(\"output.zip\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "p-plGoNvkn2L"
      },
      "outputs": [],
      "source": [
        "#@title Remove output folder\n",
        "%rm -r output"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "nst-vid.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}