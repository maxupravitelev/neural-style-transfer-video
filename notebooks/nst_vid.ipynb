{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "X9uqTXA-guxV"
      },
      "outputs": [],
      "source": [
        "#@title Setup the app\n",
        "# install packages\n",
        "!pip install tensorflow\n",
        "!pip install opencv-python\n",
        "!pip install tensorflow_hub\n",
        "!pip install matplotlib\n",
        "!pip install numpy\n",
        "!pip install Pillow\n",
        "\n",
        "# download tf model\n",
        "!curl -L https://tfhub.dev/google/magenta/arbitrary-image-stylization-v1-256/2?tf-hub-format=compressed --output model.tar.gz\n",
        "!mkdir tf_model\n",
        "!tar -xf model.tar.gz -C tf_model/\n",
        "\n",
        "!git clone https://github.com/maxupravitelev/neural-style-transfer-video.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qbfscJz8zAB_"
      },
      "source": [
        "The output video files have a rather low resolution, due to how the actual neural style transfer is handled. You can upscale the video files either by simple upscaling or by utilizing the [Image Super Resolution](https://github.com/idealo/image-super-resolution) package. If you want to use the latter, please run the cell below and click on \"Restart Runtime\" once it's done."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "DuDJ44JdzDk6"
      },
      "outputs": [],
      "source": [
        "#@title Optional: Install the Image Super Resolution package\n",
        "!pip install ISR\n",
        "!pip install 'h5py==2.10.0' --force-reinstall"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "w9qX1X4Kh26u"
      },
      "outputs": [],
      "source": [
        "#@title Run the app\n",
        "import os\n",
        "import cv2\n",
        "import logging\n",
        "\n",
        "import functools\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "import PIL\n",
        "import os.path\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "input_file_path = \"testvid.mp4\" #@param {type:\"string\"}\n",
        "filter_path = \"frame1.png\" #@param {type:\"string\"}\n",
        "output_max_size = 256 #@param {type:\"number\"}\n",
        "resize_factor = 4 #@param {type:\"number\"}\n",
        "use_superres = True #@param {type:\"boolean\"}\n",
        "\n",
        "logging.basicConfig(level=logging.DEBUG, datefmt='%Y-%m-%d:%H:%M:%S', format='%(asctime)s | %(levelname)s | %(name)s | LINE %(lineno)d: %(message)s')\n",
        "log = logging.getLogger(__name__)\n",
        "log.debug('Logging initialized')\n",
        "\n",
        "\n",
        "class FrameExtractor:\n",
        "    def __init__(self, input_video_path:str) -> None:\n",
        "\n",
        "        self.input_video_path:str = input_video_path\n",
        "\n",
        "        self.input_video_filename:str = ''\n",
        "\n",
        "        self.extracted_frames_path:str = ''\n",
        "\n",
        "        log.debug('FrameExtractor initialized')\n",
        "\n",
        "    def create_subfolder(self):\n",
        "        path_string_length:str = len(self.input_video_path)\n",
        "\n",
        "        self.input_video_filename = self.input_video_path[:path_string_length - 4] # delete file extension from string\n",
        "\n",
        "        parent_dir = 'output/extracted_frames/'\n",
        "\n",
        "        self.extracted_frames_path = os.path.join(parent_dir, self.input_video_filename)\n",
        "\n",
        "        if not os.path.exists(self.extracted_frames_path):\n",
        "            try:\n",
        "                os.makedirs(self.extracted_frames_path)\n",
        "                log.debug(f'Output path for resized frames: {self.extracted_frames_path}')\n",
        "            except Exception as e:\n",
        "                log.error(f'Output path for resized frames FAILED: {e}')\n",
        "\n",
        "\n",
        "\n",
        "    def extract_frames(self) -> str:\n",
        "                \n",
        "        cap = cv2.VideoCapture(self.input_video_path)\n",
        "\n",
        "        ret, frame = cap.read()\n",
        "        \n",
        "        if not ret:\n",
        "            log.error(f'File is not available at: {self.input_video_path}')\n",
        "\n",
        "        self.create_subfolder()\n",
        "        \n",
        "        cap = cv2.VideoCapture(self.input_video_path)\n",
        "\n",
        "        file_count:int = 0\n",
        "\n",
        "        while True:\n",
        "            ret, image = cap.read()\n",
        "\n",
        "            if not ret:\n",
        "                break\n",
        "\n",
        "            cv2.imwrite(os.path.join(self.extracted_frames_path, f\"frame{file_count}.png\"), image)     \n",
        "            log.debug(f\"{file_count} frames extracted\")\n",
        "            file_count += 1\n",
        "\n",
        "        log.info(f\"{file_count} images are extracted in {self.extracted_frames_path}.\")\n",
        "\n",
        "        return self.extracted_frames_path, self.input_video_filename\n",
        "\n",
        "\n",
        "# FrameExtractor('1.mp4').extract_frames()\n",
        "\n",
        "class NeuralStyleTransferHandler:\n",
        "    def __init__(self, extracted_frames_path:str, input_video_filename:str) -> None:\n",
        "        os.environ['CUDA_VISIBLE_DEVICES']='-1'    # disable gpu\n",
        "\n",
        "        # Load TF-Hub module\n",
        "\n",
        "        # TODO: check if downloaded and set up on first startup, load from local afterwards\n",
        "        hub_handle = 'https://tfhub.dev/google/magenta/arbitrary-image-stylization-v1-256/2'\n",
        "        #hub_handle = 'models/arbv1'\n",
        "        self.hub_module = hub.load(hub_handle)\n",
        "\n",
        "        self.extracted_frames_path = extracted_frames_path\n",
        "        self.input_video_filename = input_video_filename\n",
        "\n",
        "        parent_dir = 'output/stylized_frames/'\n",
        "\n",
        "        self.stylized_frames_path = os.path.join(parent_dir, input_video_filename)\n",
        "\n",
        "        if not os.path.exists(self.stylized_frames_path):\n",
        "            try:\n",
        "                os.makedirs(self.stylized_frames_path)\n",
        "                log.debug(f'Output path for stylized frames: {self.stylized_frames_path}')\n",
        "            except Exception as e:\n",
        "                log.error(f'Output path for stylized frames FAILED: {e}')\n",
        "\n",
        "        log.debug('NeuralStyleTransferHandler initialized')\n",
        "\n",
        "\n",
        "    # TODO\n",
        "    # def create_subfolder(self):\n",
        "\n",
        "\n",
        "    def crop_center(self, image):\n",
        "        '''Returns a cropped square image.'''\n",
        "        shape = image.shape\n",
        "        new_shape = min(shape[1], shape[2])\n",
        "        offset_y = max(shape[1] - shape[2], 0) // 2\n",
        "        offset_x = max(shape[2] - shape[1], 0) // 2\n",
        "        image = tf.image.crop_to_bounding_box(\n",
        "            image, offset_y, offset_x, new_shape, new_shape)\n",
        "        return image\n",
        "\n",
        "\n",
        "    def img_scaler(self, image, max_dim = output_max_size):\n",
        "\n",
        "        # Casts a tensor to a new type.\n",
        "        original_shape = tf.cast(tf.shape(image)[:-1], tf.float32)\n",
        "\n",
        "        # Creates a scale constant for the image\n",
        "        scale_ratio = max_dim / max(original_shape)\n",
        "\n",
        "        # Casts a tensor to a new type.\n",
        "        new_shape = tf.cast(original_shape * scale_ratio * 1, tf.int32)\n",
        "\n",
        "        # Resizes the image based on the scaling constant generated above\n",
        "        return tf.image.resize(image, new_shape)\n",
        "\n",
        "\n",
        "    @functools.lru_cache(maxsize=None)\n",
        "    def load_image(self, image_url, image_size=(256, 256), preserve_aspect_ratio=True):\n",
        "        '''Loads and preprocesses images.'''\n",
        "        # Cache image file locally.\n",
        "        #image_path = tf.keras.utils.get_file(os.path.basename(image_url)[-128:], image_url)\n",
        "        image_path = image_url\n",
        "        # Load and convert to float32 numpy array, add batch dimension, and normalize to range [0, 1].\n",
        "        img = tf.io.decode_image(\n",
        "            tf.io.read_file(image_path),\n",
        "            channels=3, dtype=tf.float32)\n",
        "        \n",
        "\n",
        "        #img = crop_center(img)\n",
        "        img = self.img_scaler(img)\n",
        "\n",
        "        #img = tf.image.resize(img, image_size, preserve_aspect_ratio=True)\n",
        "        return img[tf.newaxis, ...]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def stylize_batch(self, mode:str,  filter_path: str):\n",
        "\n",
        "        foldername = self.extracted_frames_path\n",
        "        files_in_folder = len([file for file in os.listdir(f'{foldername}/')])\n",
        "\n",
        "        if mode == \"stylize_by_all_filters\":\n",
        "            stylized_folder = f'output/stylized_frames/{self.input_video_filename}_all_filter'\n",
        "        else: \n",
        "            stylized_folder = f'output/stylized_frames/{self.input_video_filename}'\n",
        "\n",
        "        if not os.path.exists(stylized_folder):\n",
        "            os.mkdir(stylized_folder)\n",
        "\n",
        "        for i in range(files_in_folder):\n",
        "\n",
        "            if mode == 'stylize_by_all_filters':\n",
        "\n",
        "                #content_image_url: str = f'{self.extracted_frames_path}/frame{place_in_folder}.png'\n",
        "                style_image_url: str = f'filter/{i}.jpg'  \n",
        "            \n",
        "            elif mode=='stylize_by_filter':\n",
        "                content_image_url: str = f'{self.extracted_frames_path}/frame{i}.png'\n",
        "                style_image_url: str = filter_path\n",
        "            \n",
        "            output_image_size: int = 512\n",
        "\n",
        "\n",
        "            # The content image size can be arbitrary.\n",
        "            content_img_size = (output_image_size, output_image_size)\n",
        "            # The style prediction model was trained with image size 256 and it's the \n",
        "            # recommended image size for the style image (though, other sizes work as \n",
        "            # well but will lead to different results).\n",
        "            style_img_size = (256, 256)  # Recommended to keep it at 256.\n",
        "\n",
        "            content_image = self.load_image(content_image_url, content_img_size)\n",
        "            style_image = self.load_image(style_image_url, style_img_size)\n",
        "\n",
        "            style_image = tf.nn.avg_pool(style_image, ksize=[3,3], strides=[1,1], padding='SAME')\n",
        "\n",
        "\n",
        "            outputs = self.hub_module(tf.constant(content_image), tf.constant(style_image))\n",
        "\n",
        "            stylized_image = outputs[0]\n",
        "            squeezed_image = tf.squeeze(stylized_image)\n",
        "            \n",
        "            tf.keras.preprocessing.image.save_img(f'{self.stylized_frames_path}/frame{i}.png', squeezed_image)\n",
        "            log.debug(f\"{i} frames stylized\")\n",
        "\n",
        "        return self.stylized_frames_path\n",
        "\n",
        "class ImageResizer:\n",
        "    def __init__(self, styled_frames_path:str, input_video_filename:str) -> None:\n",
        "\n",
        "        self.styled_frames_path = styled_frames_path\n",
        "        self.files_in_folder = len([file for file in os.listdir(f'{self.styled_frames_path}/')])\n",
        "\n",
        "        self.input_video_filename = input_video_filename\n",
        "        \n",
        "        self.resized_frames_path = ''\n",
        "\n",
        "        self.create_subfolder()\n",
        "\n",
        "\n",
        "    def create_subfolder(self):\n",
        "\n",
        "        # path_string_length:str = len(self.input_video_filename)\n",
        "\n",
        "        # self.input_video_filename = self.input_video_filename[:path_string_length - 4] # delete file extension from string\n",
        "\n",
        "        parent_dir = 'output/resized_frames/'\n",
        "\n",
        "        self.resized_frames_path = os.path.join(parent_dir, self.input_video_filename)\n",
        "\n",
        "        if not os.path.exists(self.resized_frames_path):\n",
        "            try:\n",
        "                os.makedirs(self.resized_frames_path)\n",
        "                log.debug(f'Output path for resized frames: {self.resized_frames_path}')\n",
        "            except Exception as e:\n",
        "                log.error(f'Output path for resized frames FAILED: {e}')\n",
        "\n",
        "\n",
        "    def resize(self, resize_factor=2):\n",
        "\n",
        "        for file_count in range(self.files_in_folder):\n",
        "            image_path = self.styled_frames_path + '/' + f'frame{file_count}.png'\n",
        "\n",
        "            img = Image.open(image_path)\n",
        "            img = img.resize((img.size[0] * resize_factor, img.size[1] * resize_factor)) # (width, height)\n",
        "\n",
        "            img.save(self.resized_frames_path + '/' + f'frame{file_count}.png')\n",
        "            \n",
        "            log.debug(f\"{file_count} frames resized\")\n",
        "\n",
        "        return self.resized_frames_path\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def resize_superres(self, resize_factor):\n",
        "\n",
        "        import numpy as np\n",
        "        # import sys\n",
        "        # sys.path.append('..')\n",
        "        from ISR.models import RDN, RRDN\n",
        "\n",
        "        #model = RDN(weights='noise-cancel')\n",
        "        #model = RRDN(weights='gans')\n",
        "        model = RDN(weights='psnr-small')\n",
        "        #model = RDN(weights='psnr-large')\n",
        "\n",
        "        for file_count in range(self.files_in_folder):\n",
        "            image_path = self.styled_frames_path + '/' + f'frame{file_count}.png'\n",
        "\n",
        "            img = Image.open(image_path)\n",
        "\n",
        "            img.resize(size=(img.size[0]*resize_factor, img.size[1]*resize_factor), resample=Image.BICUBIC)\n",
        "            sr_img = model.predict(np.array(img))\n",
        "\n",
        "            new_image = Image.fromarray(sr_img)\n",
        "            new_image.save(f'{self.resized_frames_path}/frame{file_count}.png')\n",
        "            \n",
        "            log.debug(log.debug(f\"{file_count} frames resized\"))\n",
        "            \n",
        "        return self.resized_frames_path\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class FrameCombiner:\n",
        "    def __init__(self, styled_frames_path:str, input_video_filename:str) -> None:\n",
        "        \n",
        "        self.styled_frames_path:str = styled_frames_path\n",
        "        self.input_video_filename:str = input_video_filename\n",
        "        \n",
        "        log.debug('FrameCombiner initialized')\n",
        "        \n",
        "\n",
        "    def combine_frames(self, filtername):\n",
        "\n",
        "        img = cv2.imread(f'{self.styled_frames_path}/frame0.png', 0)\n",
        "\n",
        "        # choose codec according to format needed\n",
        "        fourcc = cv2.VideoWriter_fourcc(*'mp4v') \n",
        "        video = cv2.VideoWriter(f'{self.input_video_filename}_stylized_filter{filtername}.mp4', fourcc, 24, (img.shape[1], img.shape[0]))\n",
        "\n",
        "        files_in_folder = len([file for file in os.listdir(f'{self.styled_frames_path}/')])\n",
        "\n",
        "        for frame_count in range(0, files_in_folder):\n",
        "            img = cv2.imread(f'{self.styled_frames_path}/frame{frame_count}.png')\n",
        "            video.write(img)\n",
        "            log.debug(f'{frame_count} frames combined')\n",
        "\n",
        "        cv2.destroyAllWindows()\n",
        "        video.release()\n",
        "\n",
        "\n",
        "def main():\n",
        "\n",
        "    #global filter_path, image_file_path\n",
        "\n",
        "    # extract frames in folder\n",
        "    extracted_frames_path, input_video_filename = FrameExtractor(input_file_path).extract_frames()\n",
        "\n",
        "    # nst all frames in folder\n",
        "    styled_frames_path = NeuralStyleTransferHandler(extracted_frames_path, input_video_filename).stylize_batch('stylize_by_filter', filter_path)\n",
        "\n",
        "    # styled_frames_path = NeuralStyleTransferHandler(extracted_frames_path, input_video_filename).stylize_batch('stylize_by_filter', place_in_folder=filtername)\n",
        "    # styled_frames_path = NeuralStyleTransferHandler(extracted_frames_path='output/extracted_frames/1', input_video_filename='1').stylize_batch('stylize_by_filter', place_in_folder=70)\n",
        "\n",
        "\n",
        "    # optional: resize all frames in folder\n",
        "    if resize_factor is not 1:\n",
        "        if use_superres is True:\n",
        "            resized_frames_path = ImageResizer(styled_frames_path, input_video_filename).resize_superres(resize_factor)\n",
        "            styled_frames_path = resized_frames_path\n",
        "        else:\n",
        "            resized_frames_path = ImageResizer(styled_frames_path, input_video_filename).resize(resize_factor)\n",
        "            styled_frames_path = resized_frames_path\n",
        "\n",
        "\n",
        "    # combine all frames in video file\n",
        "    FrameCombiner(styled_frames_path, input_video_filename).combine_frames(filter_path)\n",
        "    # test = FrameCombiner(resized_frames_path, input_video_filename).combine_frames(filter_path)\n",
        "    #test = FrameCombiner('output/resized_frames/2', '2').combine_frames(filter_path)\n",
        "\n",
        "\n",
        "main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "k4X_UyJ4p0H6"
      },
      "outputs": [],
      "source": [
        "#@title Download all output as a zip file\n",
        "!zip -r ./output.zip ./output\n",
        "\n",
        "from google.colab import files\n",
        "files.download(\"output.zip\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "p-plGoNvkn2L"
      },
      "outputs": [],
      "source": [
        "#@title Remove output folder\n",
        "%rm -r output"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "nst-vid.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
